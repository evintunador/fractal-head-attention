{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918.592K parameters\n",
      "ModelConfig(dim=64, device='cpu', tokenizer='bpe', vocab_len=8192, num_layers=4, second_resid_norm=False, mlp_hidden_mult=8, mlp_bias=False, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=3, num_kv_heads=1, head_dim=64, theta=10000, max_seq_len=512, fractal_split=2, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06, max_batch_size=1)\n",
      "Model(\n",
      "  (token_embedder): Embedding(8195, 64)\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x Layer(\n",
      "      (pre_attn_norm): Norm()\n",
      "      (attn): FHA(\n",
      "        (Wq): Linear(in_features=64, out_features=192, bias=False)\n",
      "        (Wk): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (Wv): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (Wo): Linear(in_features=192, out_features=64, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=64, out_features=341, bias=False)\n",
      "        (Wgate): Linear(in_features=64, out_features=341, bias=False)\n",
      "        (Wdown): Linear(in_features=341, out_features=64, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# pretrained model options:\n",
    "# - a 1m parameter model trained for 1000 iters: 'FHA_1m_short_and_thicc'\n",
    "name = 'FHA_1m_short_and_thicc'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a366b1fc-b620-45a0-8b42-71bdca18906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c202ea0-e64d-4367-a4a6-102756fe63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once| |upon| |a| |ti|me|, |th|er|e| |was| |a| |boy| |na|me|d| |Tim|. \n"
     ]
    }
   ],
   "source": [
    "# take a look at the tokenizer\n",
    "prompt = \"Once upon a time, there was a boy named Tim. \"\n",
    "print(tokenizer.display(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b13a76-50f8-48b6-b7cf-9097d307c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a boy named Tim. Tim had a big tree with his mom. Tim had a big cat with a big dog, and they were very happy. One day, Tim found a big tree of a big bird. The cat saw a big pictures to help him. He wanted to do it. He did not want to help the big branches the tree. Tim and Max ran to the tree, and he came to the sky. He felt sad, the snake and said, \"Thank you you, Tim! I can is the bird and it with the pretty so yummy to go to the car. He tried to play with his friends and the big tree.\n",
      "In the end, he was sad and had fun together friends with the tree and they had to be best friends. They had so much fun and had a big fish in the backet with the ball in the park to find some from the park. The cat was not a big sing of the tree. The bird said and the cat and he was not good to be things to play with his best with him. They\n"
     ]
    }
   ],
   "source": [
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    temperature = 0.7,\n",
    "    #memory_saver_div = 8,\n",
    "    top_p = 0.9,\n",
    "    top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114de8bf-ab76-460d-8c37-ebe368b47e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
